{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install ultralytics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3FbgiYod9860",
        "outputId": "54570a16-b908-40e7-b1ff-35039bb7016d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.2.79-py3-none-any.whl.metadata (41 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/41.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0.0,>=1.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.26.4)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.10.0.84)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.13.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.3.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.18.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.5)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.1.4)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.1)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.5-py3-none-any.whl.metadata (8.9 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.7.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2024.6.1)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2.3.1)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Downloading ultralytics-8.2.79-py3-none-any.whl (869 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m869.1/869.1 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Downloading ultralytics_thop-2.0.5-py3-none-any.whl (25 kB)\n",
            "Using cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl (19.7 MB)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ultralytics-thop, ultralytics\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.6.20 nvidia-nvtx-cu12-12.1.105 ultralytics-8.2.79 ultralytics-thop-2.0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import random\n",
        "from tqdm.notebook import tqdm"
      ],
      "metadata": {
        "id": "uIr_tcZn-GhV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qXJ-PYdj-N6G",
        "outputId": "eb7206ad-beb4-4582-c54f-3ad0d01005a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "from ultralytics import YOLO\n",
        "import os\n",
        "\n",
        "# paths to directories and model weights\n",
        "image_dir = '/content/gdrive/MyDrive/object_detection/datasets/test2/images'\n",
        "output_dir = '/content/gdrive/MyDrive/object_detection/datasets2/inference2'\n",
        "person_weights = '/content/gdrive/MyDrive/object_detection/datasets2/training_results/person_detection_22/weights/best.pt'\n",
        "ppe_weights = '/content/gdrive/MyDrive/object_detection/datasets2/training_results/ppe_detection_22/weights/best.pt'\n",
        "\n",
        "# function to generate a color for each class\n",
        "def get_color_for_class(class_id):\n",
        "    np.random.seed(class_id)  # Seed for reproducibility\n",
        "    return tuple(np.random.randint(0, 255, 3).tolist())\n",
        "\n",
        "# function for inference\n",
        "def run_inference(image_dir, person_weights, ppe_weights, output_dir):\n",
        "    # load both the models\n",
        "    person_model = YOLO(person_weights)\n",
        "    ppe_model = YOLO(ppe_weights)\n",
        "\n",
        "    os.makedirs(output_dir, exist_ok=True) # if output folder does not exist, create it\n",
        "\n",
        "    # iterate over all images in the directory\n",
        "    for image_file in os.listdir(image_dir):\n",
        "        if not image_file.endswith(('.jpg', '.jpeg', '.png')):\n",
        "            continue\n",
        "\n",
        "        image_path = os.path.join(image_dir, image_file)\n",
        "        image = cv2.imread(image_path)\n",
        "\n",
        "        # inference for person detection\n",
        "        results = person_model(image)\n",
        "\n",
        "        for result in results:  # loop over each detection result\n",
        "            for box in result.boxes:\n",
        "                x1, y1, x2, y2 = map(int, box.xyxy[0])  # extract the bounding box coordinates\n",
        "                person_crop = image[y1:y2, x1:x2]  # crop the person region for PPE detection\n",
        "\n",
        "                # inference for PPE detection on the cropped image\n",
        "                ppe_results = ppe_model(person_crop)\n",
        "\n",
        "                for ppe_result in ppe_results:  # loop over each PPE detection result\n",
        "                    for ppe_box in ppe_result.boxes:\n",
        "                        px1, py1, px2, py2 = map(int, ppe_box.xyxy[0])  # extract the bounding box coordinates for PPE\n",
        "\n",
        "                        # adjust the PPE box coordinates to match the original image\n",
        "                        px1 += x1\n",
        "                        py1 += y1\n",
        "                        px2 += x1\n",
        "                        py2 += y1\n",
        "\n",
        "                        color = get_color_for_class(int(ppe_box.cls))  # get color for PPE class\n",
        "\n",
        "                        # draw bounding boxes on the original image\n",
        "                        label = ppe_model.names[int(ppe_box.cls)]\n",
        "                        conf = float(ppe_box.conf)  # convert tensor to float\n",
        "                        cv2.rectangle(image, (px1, py1), (px2, py2), color, 2)\n",
        "                        cv2.putText(image, f'{label} {conf:.2f}', (px1, py1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
        "\n",
        "        # draw bounding boxes for detected persons\n",
        "        for result in results:  # loop over each detection result\n",
        "            for box in result.boxes:\n",
        "                x1, y1, x2, y2 = map(int, box.xyxy[0])  # Extract the bounding box coordinates\n",
        "                color = (255, 0, 0)  # Red color for person detection\n",
        "\n",
        "                # draw bounding boxes on the original image\n",
        "                cv2.rectangle(image, (x1, y1), (x2, y2), color, 2)\n",
        "                cv2.putText(image, 'Person', (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
        "\n",
        "        # save the final image with bounding boxes\n",
        "        output_path = os.path.join(output_dir, image_file)\n",
        "        cv2.imwrite(output_path, image)\n",
        "\n",
        "# run the inference\n",
        "run_inference(image_dir, person_weights, ppe_weights, output_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lp8zMINsNy8Z",
        "outputId": "61c4ed60-e683-4b7a-bf00-c1f6615266a7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 448x640 3 persons, 1069.7ms\n",
            "Speed: 4.6ms preprocess, 1069.7ms inference, 1.0ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 640x192 1 hard-hat, 2 bootss, 484.1ms\n",
            "Speed: 1.7ms preprocess, 484.1ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x288 2 hard-hats, 2 bootss, 709.1ms\n",
            "Speed: 2.7ms preprocess, 709.1ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 288)\n",
            "\n",
            "0: 640x288 2 bootss, 708.9ms\n",
            "Speed: 3.1ms preprocess, 708.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 288)\n",
            "\n",
            "0: 448x640 3 persons, 1248.8ms\n",
            "Speed: 4.3ms preprocess, 1248.8ms inference, 1.2ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 544x640 2 hard-hats, 1 gloves, 2 bootss, 2 vests, 2045.5ms\n",
            "Speed: 3.7ms preprocess, 2045.5ms inference, 1.3ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 640x288 1 vest, 1142.0ms\n",
            "Speed: 2.4ms preprocess, 1142.0ms inference, 1.2ms postprocess per image at shape (1, 3, 640, 288)\n",
            "\n",
            "0: 640x352 1 boots, 1 vest, 1218.4ms\n",
            "Speed: 2.9ms preprocess, 1218.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 352)\n",
            "\n",
            "0: 448x640 1 person, 1074.3ms\n",
            "Speed: 4.5ms preprocess, 1074.3ms inference, 1.1ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 640x416 1 hard-hat, 1 gloves, 1 vest, 1026.6ms\n",
            "Speed: 2.9ms preprocess, 1026.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 416)\n",
            "\n",
            "0: 448x640 8 persons, 1056.4ms\n",
            "Speed: 4.6ms preprocess, 1056.4ms inference, 1.0ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 640x224 1 hard-hat, 3 bootss, 1 ppe-suit, 583.2ms\n",
            "Speed: 1.9ms preprocess, 583.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x96 1 hard-hat, 1 ppe-suit, 271.6ms\n",
            "Speed: 2.0ms preprocess, 271.6ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 96)\n",
            "\n",
            "0: 640x224 1 hard-hat, 1 boots, 577.9ms\n",
            "Speed: 3.2ms preprocess, 577.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x256 2 hard-hats, 1 ppe-suit, 623.6ms\n",
            "Speed: 2.6ms preprocess, 623.6ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x224 1 hard-hat, 2 bootss, 1 ppe-suit, 567.4ms\n",
            "Speed: 2.5ms preprocess, 567.4ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x192 2 hard-hats, 481.0ms\n",
            "Speed: 2.4ms preprocess, 481.0ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x192 1 hard-hat, 2 bootss, 497.2ms\n",
            "Speed: 2.3ms preprocess, 497.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x256 1 hard-hat, 1 ppe-suit, 648.8ms\n",
            "Speed: 2.6ms preprocess, 648.8ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 448x640 1 person, 1050.8ms\n",
            "Speed: 4.5ms preprocess, 1050.8ms inference, 0.9ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 640x320 1 hard-hat, 2 glovess, 1 vest, 766.2ms\n",
            "Speed: 2.3ms preprocess, 766.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 320)\n",
            "\n",
            "0: 448x640 1 person, 1602.2ms\n",
            "Speed: 3.3ms preprocess, 1602.2ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 640x448 1 hard-hat, 1 gloves, 1 ppe-suit, 1725.8ms\n",
            "Speed: 3.2ms preprocess, 1725.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 448)\n",
            "\n",
            "0: 448x640 9 persons, 1711.1ms\n",
            "Speed: 5.2ms preprocess, 1711.1ms inference, 1.0ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 640x256 3 bootss, 643.7ms\n",
            "Speed: 2.6ms preprocess, 643.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x224 2 bootss, 575.2ms\n",
            "Speed: 1.8ms preprocess, 575.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x224 2 bootss, 570.2ms\n",
            "Speed: 3.3ms preprocess, 570.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x256 3 bootss, 653.7ms\n",
            "Speed: 2.4ms preprocess, 653.7ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 256)\n",
            "\n",
            "0: 640x224 2 bootss, 563.9ms\n",
            "Speed: 2.7ms preprocess, 563.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 640x128 2 hard-hats, 1 boots, 365.4ms\n",
            "Speed: 1.1ms preprocess, 365.4ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 128)\n",
            "\n",
            "0: 640x192 1 boots, 491.9ms\n",
            "Speed: 1.4ms preprocess, 491.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 192)\n",
            "\n",
            "0: 640x160 (no detections), 421.3ms\n",
            "Speed: 1.3ms preprocess, 421.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 160)\n",
            "\n",
            "0: 640x224 1 hard-hat, 2 bootss, 570.2ms\n",
            "Speed: 1.7ms preprocess, 570.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 224)\n",
            "\n",
            "0: 448x640 3 persons, 1058.8ms\n",
            "Speed: 2.8ms preprocess, 1058.8ms inference, 1.4ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 640x512 1 hard-hat, 2 bootss, 1 ppe-suit, 1228.4ms\n",
            "Speed: 3.2ms preprocess, 1228.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 512)\n",
            "\n",
            "0: 640x512 1 hard-hat, 2 bootss, 1 ppe-suit, 1244.8ms\n",
            "Speed: 3.1ms preprocess, 1244.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 512)\n",
            "\n",
            "0: 640x448 1 hard-hat, 2 bootss, 1 ppe-suit, 1083.2ms\n",
            "Speed: 3.7ms preprocess, 1083.2ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 448)\n",
            "\n",
            "0: 448x640 2 persons, 1565.5ms\n",
            "Speed: 3.5ms preprocess, 1565.5ms inference, 1.3ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 640x576 2 hard-hats, 2 vests, 2176.4ms\n",
            "Speed: 5.1ms preprocess, 2176.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 576)\n",
            "\n",
            "0: 640x448 2 vests, 1515.5ms\n",
            "Speed: 3.1ms preprocess, 1515.5ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 448)\n",
            "\n",
            "0: 448x640 3 persons, 1044.3ms\n",
            "Speed: 3.1ms preprocess, 1044.3ms inference, 0.9ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 640x320 2 hard-hats, 2 glovess, 1 ppe-suit, 785.7ms\n",
            "Speed: 2.4ms preprocess, 785.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 320)\n",
            "\n",
            "0: 512x640 1 hard-hat, 1 gloves, 1242.0ms\n",
            "Speed: 4.0ms preprocess, 1242.0ms inference, 1.1ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "0: 544x640 1 hard-hat, 1 gloves, 1292.6ms\n",
            "Speed: 3.8ms preprocess, 1292.6ms inference, 1.1ms postprocess per image at shape (1, 3, 544, 640)\n",
            "\n",
            "0: 448x640 1 person, 1065.4ms\n",
            "Speed: 3.3ms preprocess, 1065.4ms inference, 1.0ms postprocess per image at shape (1, 3, 448, 640)\n",
            "\n",
            "0: 640x384 1 hard-hat, 2 glovess, 2 bootss, 1 ppe-suit, 914.4ms\n",
            "Speed: 2.6ms preprocess, 914.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 384)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ggnfvlfc2JFv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}